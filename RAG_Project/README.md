# ğŸ¯ RAG Q&A System

[![AWS Bedrock](https://img.shields.io/badge/AWS-Bedrock-FF9900?logo=amazonaws&style=for-the-badge)](https://aws.amazon.com/bedrock/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3-blue?logo=chainlink&style=for-the-badge)](https://python.langchain.com/)
[![FAISS](https://img.shields.io/badge/FAISS-Vector_Search-00C7B7?style=for-the-badge)](https://github.com/facebookresearch/faiss)

A production-ready **Retrieval-Augmented Generation** system that answers questions about PDF documents using semantic search and LLM-powered generation.

## How It Works

```
PDF Document
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Loader  â”‚â”€â”€â”€â”€â–¶â”‚ Text Splitter â”‚â”€â”€â”€â”€â–¶â”‚  Titan V2    â”‚
â”‚  (PyPDF)     â”‚     â”‚ (1000 chars)  â”‚     â”‚  Embeddings  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  FAISS Index  â”‚
                                        â”‚ (Vector Store)â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
User Question â”€â”€â–¶ Embed â”€â”€â–¶ MMR Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  Claude 3     â”‚
                                        â”‚  Sonnet (LLM) â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                          Answer + Sources
```

## Prerequisites

- **Python 3.10+**
- **AWS Account** with Bedrock access enabled for:
  - `amazon.titan-embed-text-v2:0` (embeddings)
  - `anthropic.claude-3-sonnet-20240229-v1:0` (LLM)
- **AWS CLI** configured with a named profile (default: `default`)

## Quick Start

```bash
# 1. Clone and navigate
cd RAG_Project

# 2. Create a virtual environment
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # macOS/Linux

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment
copy .env.example .env        # Windows
# cp .env.example .env        # macOS/Linux
# Edit .env with your AWS profile and preferences

# 5. Run the app
streamlit run rag_frontend.py
```

## Project Structure

```
RAG_Project/
â”œâ”€â”€ rag_backend.py      # Core RAG pipeline (load â†’ split â†’ embed â†’ index â†’ query)
â”œâ”€â”€ rag_frontend.py     # Streamlit chat interface
â”œâ”€â”€ requirements.txt    # Pinned Python dependencies
â”œâ”€â”€ .env.example        # Environment variable template
â”œâ”€â”€ .gitignore          # Git ignore rules
â”œâ”€â”€ RAG.gif             # Architecture animation
â””â”€â”€ README.md
```

## Configuration

All settings are configurable via the `.env` file:

| Variable | Default | Description |
|----------|---------|-------------|
| `AWS_PROFILE` | `default` | AWS CLI profile name |
| `AWS_REGION` | `us-east-1` | AWS region for Bedrock |
| `EMBEDDING_MODEL_ID` | `amazon.titan-embed-text-v2:0` | Bedrock embedding model |
| `LLM_MODEL_ID` | `anthropic.claude-3-sonnet-20240229-v1:0` | Bedrock LLM model |
| `PDF_SOURCE_URL` | UPL Leave Policy PDF | URL of the PDF to index |
| `CHUNK_SIZE` | `1000` | Characters per text chunk |
| `CHUNK_OVERLAP` | `200` | Overlap between chunks |
| `SEARCH_TYPE` | `mmr` | Retrieval strategy (`mmr` or `similarity`) |
| `SEARCH_K` | `4` | Number of chunks to retrieve |
| `SEARCH_FETCH_K` | `8` | Candidates for MMR diversity selection |

## Tech Stack

| Component | Technology |
|-----------|-----------|
| **Embeddings** | Amazon Titan Embed Text V2 (1024-dim) |
| **LLM** | Anthropic Claude 3 Sonnet via Bedrock |
| **Vector Store** | FAISS (in-memory, local) |
| **Orchestration** | LangChain 0.3 (`RetrievalQA` chain) |
| **Document Loader** | PyPDF via `langchain-community` |
| **Text Splitter** | `RecursiveCharacterTextSplitter` |
| **Retrieval** | MMR (Max Marginal Relevance) |
| **Frontend** | Streamlit with chat interface |

## Architecture Diagram

![RAG Architecture](./RAG.gif)

---
*Maintained by Phani Kolla*
